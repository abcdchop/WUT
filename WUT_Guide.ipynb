{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, Welcome to the Internal Guide to this Uncertainy Library-- This python notebook should contain everything a man needs to use and alter this package as he sees fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this, we are going to use the same datasets for regression and classification. The regression dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip and the classifiction dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz. You will obviously need to get these to continue this notebook\n",
    "\n",
    "## NOTE: HAD to change the extention of covtype to .txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library has a dependency on this repo here: https://github.com/cpmpercussion/keras-mdn-layer. Shoutout to compercussion on github for making the mdn layer, which is extremely good.\n",
    "\n",
    "# NOTE:  python3 -m pip install keras-mdn-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might note: the scores here in the default training are really bad-- Train for more epochs! This is a demo of how to use stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import WUT as WUT\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515345, 90) (515345,)\n",
      "(581012, 54) (581012, 7)\n"
     ]
    }
   ],
   "source": [
    "'Here we make a Regression Dataset'\n",
    "\n",
    "text_file = open(\"Datasets/YearPredictionMSD.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "alldata = [[float(x) for x in line.split(',')] for line in lines]\n",
    "text_file.close()\n",
    "alldata = np.array(alldata)\n",
    "Yreg = tf.convert_to_tensor(alldata[:,0], dtype = tf.float32)\n",
    "Xreg = tf.convert_to_tensor(alldata[:,1:], dtype = tf.float32)\n",
    "# Yreg = (Yreg - tf.math.reduce_mean(Yreg))/tf.math.reduce_std(Yreg)\n",
    "# Xreg = (Xreg - tf.math.reduce_mean(Xreg, axis=0, keepdims=True))/tf.math.reduce_std(Xreg, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "# Yreg = Yreg/tf.reduce_max(Yreg)\n",
    "\n",
    "print(Xreg.shape, Yreg.shape)\n",
    "\n",
    "'Here we make a classification Dataset'\n",
    "\n",
    "\n",
    "# text_file = open(\"Datasets/covtype.txt\", \"r\")\n",
    "# lines = text_file.readlines()\n",
    "# alldata = [[float(x) for x in line.split(',')] for line in lines]\n",
    "# text_file.close()\n",
    "# alldata = np.array(alldata)\n",
    "# ImYclass = alldata[:,-1].astype(int)-1\n",
    "# Xclass = (alldata[:,:-1])\n",
    "# Yclass = np.zeros((ImYclass.size, ImYclass.max()+1))\n",
    "# Yclass[np.arange(ImYclass.size), ImYclass] = 1\n",
    "# Yclass = tf.convert_to_tensor(Yclass, dtype = tf.float32)\n",
    "# Xclass = tf.convert_to_tensor(Xclass, dtype = tf.float32)\n",
    "\n",
    "# print(Xclass.shape, Yclass.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're gonna make two models, very simple bois for regression and classification, respectively. IMPORTANT NOTE that in these networks, the output to the call is the output of the last Dense Layer. This is the only requirement for this package to work with your models. (Ensembles and Dropout should work for anything, though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RegModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RegModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(60, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(30, activation=tf.nn.relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "class ClassModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ClassModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(36, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(36, activation=tf.nn.relu)\n",
    "        self.dense3 = tf.keras.layers.Dense(7, activation = tf.nn.softmax)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could then train these guys normally: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16105/16105 [==============================] - 10s 619us/step - loss: 104848.9937\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10871.5703\n",
      "10871.5703125\n",
      "[[2033.3293]\n",
      " [2151.5332]\n",
      " [2091.0142]\n",
      " [1992.1365]\n",
      " [2150.904 ]]\n"
     ]
    }
   ],
   "source": [
    "regmodel = RegModel()\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.MSE)\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg[0:5], Yreg[0:5]))\n",
    "print(regmodel.predict(Xreg[0:5]))\n",
    "\n",
    "\n",
    "# classmodel = ClassModel()\n",
    "# classmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy())\n",
    "# classmodel.fit(Xclass, Yclass)\n",
    "# print(classmodel.evaluate(Xclass[0:5], Yclass[0:5]))\n",
    "# print(classmodel.predict(Xclass[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could wrap them in an ensemble first \n",
    "(that second argument in the wrapper is the number of ensembles you'd like). \n",
    "\n",
    "The output will now be a mean and variance of ensemble outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Fails with tf 2.1 No module named 'tensorflow.python.keras.layers.ops'\" Needs to upgrade to >=2.2. Currently, testing using 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16105/16105 [==============================] - 10s 624us/step - loss: 115265.2788\n",
      "16105/16105 [==============================] - 10s 636us/step - loss: 89795.9651\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9296.6826\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2475.5317\n",
      "[9296.6826171875, 2475.53173828125]\n",
      "tf.Tensor(\n",
      "[[[2031.4398  ]\n",
      "  [  24.871704]]\n",
      "\n",
      " [[2050.9312  ]\n",
      "  [  39.771606]]\n",
      "\n",
      " [[2055.4097  ]\n",
      "  [  43.64148 ]]\n",
      "\n",
      " [[1978.0267  ]\n",
      "  [  31.785034]]\n",
      "\n",
      " [[2128.9067  ]\n",
      "  [  32.361084]]], shape=(5, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from WUT.Ensemble import Ensemble\n",
    "\n",
    "regmodel = Ensemble(RegModel, 2)\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.MSE)\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg[0:5], Yreg[0:5]))\n",
    "print(regmodel.predict(Xreg[0:5]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# classmodel = Ensemble(ClassModel, 2)\n",
    "# classmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy())\n",
    "# classmodel.fit(Xclass, Yclass)\n",
    "# print(classmodel.evaluate(Xclass[0:5], Yclass[0:5]))\n",
    "# print(classmodel.predict(Xclass[0:5]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could wrap them in an MC dropout scheme first \n",
    "\n",
    "(second arg is dropout rate, \n",
    "\n",
    "third arg defaults to what is below, and determines what types of layers dropout is applied to-- this hasn't been tested on everything, but Dense layers are definitely safe)\n",
    "\n",
    "The output will now be a mean and variance of multiple trials through the network, with trials obviously determining trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16105/16105 [==============================] - 11s 696us/step - loss: 255529.8833\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 43890.1797\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 57495.8945\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 157584.3438\n",
      "[43890.1796875, 57495.89453125, 157584.34375]\n",
      "tf.Tensor(\n",
      "[[[1718.5996  ]\n",
      "  [ 473.48505 ]]\n",
      "\n",
      " [[2324.478   ]\n",
      "  [ 103.155396]]\n",
      "\n",
      " [[1930.6385  ]\n",
      "  [ 106.90381 ]]\n",
      "\n",
      " [[2000.2935  ]\n",
      "  [ 118.76782 ]]\n",
      "\n",
      " [[2250.0103  ]\n",
      "  [ 216.67645 ]]], shape=(5, 2, 1), dtype=float32)\n",
      "18157/18157 [==============================] - 12s 645us/step - loss: 12.8433\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7f11e43a86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.5754\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4599\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1505\n",
      "[2.5753939151763916, 2.4598770141601562, 3.150456190109253]\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f11e42462f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[[2.3829305e-01 5.9207106e-01 9.7912557e-02 7.5984714e-03 1.4000494e-02\n",
      "   4.4260804e-02 5.8635855e-03]\n",
      "  [7.7789672e-02 8.2211971e-02 9.7684808e-02 7.5439024e-03 9.4821285e-03\n",
      "   4.4090934e-02 1.1998494e-03]]\n",
      "\n",
      " [[3.1841362e-01 6.7198694e-01 2.6341496e-04 5.3508898e-05 4.4400590e-03\n",
      "   2.0821295e-04 4.6342975e-03]\n",
      "  [4.4009984e-03 1.4547406e-03 1.9797857e-04 3.2173601e-05 1.4965509e-03\n",
      "   1.5893567e-04 1.0606315e-03]]\n",
      "\n",
      " [[1.9156094e-01 7.6364744e-01 1.0298616e-02 4.3134470e-04 1.2862938e-02\n",
      "   1.2706689e-02 8.4920758e-03]\n",
      "  [9.4559230e-02 1.3927183e-01 1.0298615e-02 4.3005071e-04 1.2862939e-02\n",
      "   1.2705098e-02 8.4158881e-03]]\n",
      "\n",
      " [[2.3705307e-01 6.1923170e-01 8.1563324e-02 6.1213640e-03 1.4503607e-02\n",
      "   3.5986818e-02 5.5401083e-03]\n",
      "  [4.0992647e-02 1.0165563e-01 8.1557937e-02 6.0905418e-03 1.3985964e-02\n",
      "   3.5986241e-02 5.0277044e-03]]\n",
      "\n",
      " [[2.5491953e-01 5.9327734e-01 8.2021579e-02 6.1667813e-03 1.8259594e-02\n",
      "   3.6409900e-02 8.9453319e-03]\n",
      "  [5.8859095e-02 7.5701274e-02 8.1099696e-02 6.0451250e-03 1.0229976e-02\n",
      "   3.5563163e-02 1.6224815e-03]]], shape=(5, 2, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from WUT.Dropout import Dropout\n",
    "\n",
    "regmodel = Dropout(RegModel, 0.2, dropout_layers = [tf.keras.layers.Dense])\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.MSE)\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg[0:5], Yreg[0:5]) )\n",
    "print(regmodel.predict(Xreg[0:5], trials = 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classmodel = Dropout(ClassModel, 0.2)\n",
    "classmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy())\n",
    "classmodel.fit(Xclass, Yclass)\n",
    "print(classmodel.evaluate(Xclass[0:5], Yclass[0:5]))\n",
    "print(classmodel.predict(Xclass[0:5], trials = 2) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could simply throw an additional network to predict error, as a regression\n",
    "\n",
    "(extra args:\n",
    "\n",
    "Std_Model: The model to predict variance. Defaults to a clone of input model, with activation on last layer removed)\n",
    "\n",
    "error_activation: What to replace the activation on last layer with for the Std_Model. Defaults to None\n",
    "\n",
    "one_hot: If true, will assume target values have already been converted to one_hot variables, and will not do it manually. Defaults to True.)\n",
    "\n",
    "\n",
    "The output will now be simple predicted mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function() got an unexpected keyword argument 'jit_compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fe6f343497a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mWUT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariance_Network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariance_Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mregmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariance_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Stanford/WUT/WUT/WUT/Variance_Network.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmdn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/mdn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# from tensorflow_probability.google import tfp_google  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;31m# Non-lazy load of packages that register with tensorflow or keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpkg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_maybe_nonlazy_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Forces loading the package from its lazy loader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m__dir__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbijectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/experimental/bijectors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"TensorFlow Probability experimental bijectors package.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldj_ratio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_log_det_jacobian_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldj_ratio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minverse_log_det_jacobian_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_bijectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_distribution_bijector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import,line-too-long,g-importing-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute_value\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbsoluteValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine_linear_operator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAffineLinearOperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/absolute_value.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbijector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_composite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprefer_static\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m# pylint: disable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/math/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsd_kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbessel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbessel_iv_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbessel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbessel_ive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/math/psd_kernels/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_transformed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureTransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkumaraswamy_transformed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKumaraswamyTransformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeneralizedMatern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaternFiveHalves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaternOneHalf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/math/psd_kernels/matern.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtype_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbessel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp_math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsd_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_semidefinite_kernel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPositiveSemidefiniteKernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/math/bessel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprefer_static\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorshape_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp_math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/math/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m _reduce_kahan_sum = variadic_reduce.make_variadic_reduce(\n\u001b[0;32m--> 152\u001b[0;31m     _kahan_reduction, _kahan_reduce_bwd, _kahan_reduce_tangents)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RansVirtualEnvs/Main3.5/lib/python3.6/site-packages/tensorflow_probability/python/internal/variadic_reduce.py\u001b[0m in \u001b[0;36mmake_variadic_reduce\u001b[0;34m(reducer, vjp_bwd, tangents_fn)\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;31m# Top-level `tf.function` for XLA (closed-over by the returned reduce_fn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mimplementation_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_runs_functions_eagerly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_xla_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m\"\"\"JIT-ed wrapper for TF `xla.variadic_reduce(..., reducer)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: function() got an unexpected keyword argument 'jit_compile'"
     ]
    }
   ],
   "source": [
    "from WUT.Variance_Network import Variance_Network\n",
    "\n",
    "regmodel = Variance_Network(RegModel)\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.MSE)\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg, Yreg)) \n",
    "print(regmodel.predict(Xreg[0:5]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classmodel = Variance_Network(ClassModel)\n",
    "classmodel.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.CategoricalCrossentropy())\n",
    "classmodel.fit(Xclass, Yclass)\n",
    "print(classmodel.evaluate(Xclass, Yclass))\n",
    "print(classmodel.predict(Xclass[0:5]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could fit a gaussian mixture model to this.\n",
    "Second argument here is how many gaussians you'd like to fit.\n",
    "\n",
    "Output is now a Probability distribution in posterior space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chrishealy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "16105/16105 [==============================] - 26s 2ms/step - loss: 6.6664\n",
      "16105/16105 [==============================] - 11s 701us/step - loss: 6.2689\n",
      "6.268917560577393\n",
      "tf.Tensor(\n",
      "[[1921.5614]\n",
      " [2114.6772]\n",
      " [2088.1204]\n",
      " [2074.249 ]\n",
      " [2280.48  ]], shape=(5, 1), dtype=float32)\n",
      "1/1 [==============================] - 0s 990us/step - loss: 21114667008.0000\n",
      "21114667008.0\n",
      "tf.Tensor(\n",
      "[[  -2.8682199   440.55505      -9.252266   -122.47605     285.3768\n",
      "  -189.76274     -86.552826  ]\n",
      " [   0.63337547  485.99738    -286.06485    -224.61842    -326.705\n",
      "    44.933136     -9.93264   ]\n",
      " [   1.9110353   292.4095      -83.9474        5.6412625   163.41637\n",
      "   108.41966    -209.20148   ]\n",
      " [  -1.9658955   143.63368     -38.92147     -30.871521      7.049843\n",
      "  -156.00131    -307.8017    ]\n",
      " [   2.242136   -328.57556    -191.11871      36.756676    164.90022\n",
      "   137.1727      -38.892155  ]], shape=(5, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from WUT.Gaussian_Mixtures import Gaussian_Mixtures\n",
    "\n",
    "regmodel = Gaussian_Mixtures(RegModel, 5)\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam())\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg, Yreg)) \n",
    "regression_dist = regmodel.predict(Xreg[0:5])\n",
    "print(regression_dist.sample())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classmodel = Gaussian_Mixtures(ClassModel, 5)\n",
    "classmodel.compile(optimizer = tf.keras.optimizers.Adam())\n",
    "classmodel.fit(Xclass[0:5], Yclass[0:5], epochs = 1000, verbose = False)\n",
    "print(classmodel.evaluate(Xclass[0:5], Yclass[0:5]))\n",
    "classification_dist = classmodel.predict(Xclass[0:5])\n",
    "print(classification_dist.sample())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you've got a real masochistic streak, you could run Stochastic Variational Inference Here.\n",
    "\n",
    "There are a lot of optional arguments here for those who want to get into the weeds, but I'll cover a few important ones:\n",
    "\n",
    "task: set this to 'regression' or 'classification'. Defaults to regression.\n",
    "\n",
    "one_hot: If True, assumes targets are one hot in classification case. Defaults True\n",
    "\n",
    "normalize: whether to normalize inputs and outputs, defaults to True. If you encounter nans, try fiddling with this!\n",
    "\n",
    "Returns: A probability distribution over the outputs pace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12271/12271 [==============================] - 11s 808us/step - loss: 455336.9019\n",
      "12271/12271 [==============================] - 10s 815us/step - loss: 112.7990\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7f11ef7667b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "16105/16105 [==============================] - 9s 574us/step - loss: 7941.6631\n",
      "7941.6630859375\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f11ef70fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[2037.2229]\n",
      " [1959.3247]\n",
      " [1946.5162]\n",
      " [1973.3037]\n",
      " [2035.2181]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from WUT.SVI import SVI\n",
    "\n",
    "regmodel = SVI(RegModel)\n",
    "regmodel.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001))\n",
    "regmodel.fit(Xreg, Yreg)\n",
    "print(regmodel.evaluate(Xreg, Yreg)) \n",
    "regression_dist = regmodel.predict(Xreg[0:5])\n",
    "print(regression_dist.sample())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# classmodel = SVI(ClassModel, task = 'classification', one_hot = True)\n",
    "# classmodel.compile(optimizer = tf.keras.optimizers.Adam())\n",
    "# classmodel.fit(Xclass, Yclass)\n",
    "# print(classmodel.evaluate(Xclass, Yclass))\n",
    "# classification_dist = classmodel.predict(Xclass[0:5])\n",
    "# print(classification_dist.sample())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
